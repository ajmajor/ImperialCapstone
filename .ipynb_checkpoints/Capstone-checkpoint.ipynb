{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imperial AI & Machine Learning Capstone Project  \n",
    "Submission by: **Andrew Major**  \n",
    "Student Number: **432**\n",
    "\n",
    "## 1. Problem Statement and Objective  \n",
    "\n",
    "- **Problem**: Predict customer churn (i.e., which customers are likely to leave the bank).\n",
    "- **Objective**: Develop a model that accurately predicts churn to help the bank retain valuable customers.\n",
    "\n",
    "\n",
    "## 2. Initial Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import decimal\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import capstoneFunctions as cf\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation  \n",
    "\n",
    "* **Data Collection**: Source a banking customer dataset, including features such as account balance, transaction frequency, customer demographics, etc.\n",
    "* **Data Cleaning**:\n",
    "  * Handle missing values (impute or drop).\n",
    "  * Remove irrelevant features.\n",
    "  * Check for duplicates.\n",
    "* **Data Exploration**:\n",
    "  * Understand the distribution of features.\n",
    "  * Identify potential outliers.\n",
    "### Load the dataset from .csv file  \n",
    "* Explore columns and missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rawData = pd.read_csv('./data/churn_modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look for the missing values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pd.isnull(rawData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop any irrelevant columns unlikely to influence outcome..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = rawData.drop(columns=['RowNumber', 'CustomerId', 'Surname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing  \n",
    "\n",
    "* **Feature Scaling**: Normalise numerical features (e.g., using Min-Max scaling or Z-score normalisation). After consultation, it was agreed to only scale features for the K-Nearest Neighbours model.\n",
    "* **Handling Categorical Features**:\n",
    "  * Convert categorical features to numerical using one-hot encoding.\n",
    "* **Feature Engineering**:\n",
    "  * Consider creation of new features if relevant (e.g., customer tenure, transaction frequency).\n",
    "  * Explore interactions between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Convert categorical data into numerical data\n",
    "le = LabelEncoder()\n",
    "rawData['Geography'] = le.fit_transform(rawData['Geography'])\n",
    "rawData['Gender'] = le.fit_transform(rawData['Gender'])\n",
    "\n",
    "# Scale the numerical data\n",
    "scaler = StandardScaler()\n",
    "rawData[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']] = scaler.fit_transform(rawData[['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']])\n",
    "\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into predictors and outcomes, in preparation for creation of training, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_alt = rawData.drop(columns=['Exited'])\n",
    "outcomes_alt = rawData['Exited']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distribution of outcomes, as this will influence our choice of performance metrics for the models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_alt.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target of positive churn represents approximately 20% of the total dataset; this imbalance means we will lean towards the F1 Score as a performance metric as it is impacted by both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Correlation Matix  \n",
    "* We need to determine if multi-colinearity will be an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf.correlationMatrix(outcomes_alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Selection  \n",
    "\n",
    "We will consider the following six alternative models:\n",
    "\n",
    "1. **Logistic Regression**:\n",
    "  * A simple yet interpretable model.\n",
    "  * Suitable for binary classification tasks.\n",
    "  * May need input data converted to categorical (e.g., one-hot encoding for categorical features like gender, education level).\n",
    "\n",
    "2. **Random Forest**:\n",
    "  * Ensemble method combining multiple decision trees.\n",
    "  * Handles non-linear relationships.\n",
    "  * Can handle both numerical and categorical features.\n",
    "\n",
    "3. **K-Nearest Neighbours**:\n",
    "  * KNN is easy to understand and implement.\n",
    "  * It doesnâ€™t make any underlying assumptions about the data distribution.\n",
    "  * Can learn nonlinear decision boundaries.\n",
    "\n",
    "4. **Gradient Boosting (e.g., XGBoost)**:\n",
    "  * Powerful ensemble model.\n",
    "  * Handles complex interactions.\n",
    "  * Automatically handles missing values.\n",
    "  * May not require explicit one-hot encoding.\n",
    "\n",
    "5. **Support Vector Machine**:\n",
    "  * SVC works well when there is a clear margin of separation between classes.\n",
    "  * Aims to find the optimal hyperplane that maximizes the distance between data points of different classes.\n",
    "\n",
    "6. **Neural Networks (Deep Learning)**:\n",
    "  * Complex model capable of learning intricate patterns.\n",
    "  * Requires substantial data and computational resources.\n",
    "  * Can handle both numerical and categorical features.\n",
    "\n",
    "## 5. Performance Metrics  \n",
    "\n",
    "Choose appropriate metrics to compare model performance. Given that we are predicting the minority class representing approximately 20% of the data, we are interested in:\n",
    "\n",
    "* **Precision**: Proportion of true positive predictions among all positive predictions.\n",
    "* **Recall (Sensitivity)**: Proportion of actual positives correctly predicted.\n",
    "* **F1-Score**: Harmonic mean of precision and recall.\n",
    "\n",
    "## 6. Model Training and Evaluation  \n",
    "\n",
    "* Split data into training and hold-out validation sets.\n",
    "* Tune hyperparameters (e.g., learning rate, tree depth) using full grid search and randomised grid search for comparison, with cross-validation. It was decided after consultation that the only models requiring full optimisation were the K-Nearest Neighbour and Gradient Boosting models. For programming convenience, all other models were 'optimised' through the same python module, but with a single value specified for each hperparameter; this allowed the benefitof the GridSearchCV and RandomizedSearchCV outputs to be obtained for all models.\n",
    "* Train each model with stratified k-fold cross-validation using the chosen features.\n",
    "* Evaluate models using the selected performance metrics on the hold-out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial attept totune FNN hyperparameters before full training alongside other models\n",
    "FNNresults= cf.trainFNNOnly(trialPredictors, outcomes, nEpochs=10, learningRate=0.0001, display=True, threshold=0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results, X_val, y_val = cf.trainTestCycle(outcomes_alt,outcomes_alt, stratifiedKF=True, threshold=0.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_val_scores = []\n",
    "f1_train_scores = []\n",
    "f1_scores= []\n",
    "confusion_matrices = []\n",
    "labels = []\n",
    "for model, data in results.items():\n",
    "    if model != 'FNN':\n",
    "        # confusion matrix\n",
    "        confusion_matrices.append(data['Grid']['validation']['confusion'])\n",
    "        confusion_matrices.append(data['Random']['validation']['confusion'])\n",
    "        # Best training scores\n",
    "        f1_train_scores.append(data['Grid']['bestScore'])\n",
    "        f1_train_scores.append(data['Random']['bestScore'])\n",
    "        # validation scores\n",
    "        f1_val_scores.append(data['Grid']['validation']['f1'])\n",
    "        labels.append(model + '_grid')\n",
    "        f1_val_scores.append(data['Random']['validation']['f1'])\n",
    "        labels.append(model + '_rand')\n",
    "        # data for plots\n",
    "        f1_scores.append([data['Grid']['bestScore'],data['Grid']['validation']['f1']])\n",
    "        f1_scores.append([data['Random']['bestScore'],data['Random']['validation']['f1']])\n",
    "    else:\n",
    "        # confusion matrix\n",
    "        confusion_matrices.append(data['confusion'])\n",
    "        # Best training scores\n",
    "        f1_train_scores.append(0)\n",
    "        # validation scores\n",
    "        f1_val_scores.append(data['scores']['f1'])\n",
    "        labels.append(model)\n",
    "        # data for plots\n",
    "        f1_scores.append([0, data['scores']['f1']])\n",
    "print(labels)\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "names =['Best Train', 'Validation']\n",
    "colours = ['blue', 'orange']\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(f1_scores, index=labels, columns=names)\n",
    "\n",
    "# Plot the bar chart\n",
    "ax = df.plot.bar(color=colours)\n",
    "ax.set_title(\"F1 Scores for Trained Model Comparison\")\n",
    "ax.set_xlabel(\"Models\")  # Customize x-axis label\n",
    "ax.set_ylabel(\"F1 Score\")  # Customize y-axis label\n",
    "plt.savefig('F1_Comparison.png')\n",
    "plt.show()\n",
    "# confusion matrix\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(results['SVC']['Grid']['validation']['confusion'], annot=True, fmt='g', ax=ax)\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix for SVM Classifier')\n",
    "plt.savefig('SVC_CM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = results['Logistic']['Grid']['validation']['confusion'].ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
